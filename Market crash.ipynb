{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "izsK886z1iDR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Loading dataset\n",
    "file_path = 'FinancialMarketData.xlsx'\n",
    "data = pd.ExcelFile(file_path)\n",
    "ews_data = data.parse('EWS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "4rtBF_MV1y9g",
    "outputId": "04a7647d-27b5-4132-fdbc-707d4419bc78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Data</th>\n",
       "      <th>XAU BGNL</th>\n",
       "      <th>ECSURPUS</th>\n",
       "      <th>BDIY</th>\n",
       "      <th>CRY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>Cl1</th>\n",
       "      <th>...</th>\n",
       "      <th>LP01TREU</th>\n",
       "      <th>EMUSTRUU</th>\n",
       "      <th>LF94TRUU</th>\n",
       "      <th>MXUS</th>\n",
       "      <th>MXEU</th>\n",
       "      <th>MXJP</th>\n",
       "      <th>MXBR</th>\n",
       "      <th>MXRU</th>\n",
       "      <th>MXIN</th>\n",
       "      <th>MXCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>283.25</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1388</td>\n",
       "      <td>157.26</td>\n",
       "      <td>100.56</td>\n",
       "      <td>105.86</td>\n",
       "      <td>1.6460</td>\n",
       "      <td>25.77</td>\n",
       "      <td>...</td>\n",
       "      <td>116.4635</td>\n",
       "      <td>230.5267</td>\n",
       "      <td>123.7616</td>\n",
       "      <td>1416.12</td>\n",
       "      <td>127.75</td>\n",
       "      <td>990.59</td>\n",
       "      <td>856.76</td>\n",
       "      <td>224.33</td>\n",
       "      <td>217.34</td>\n",
       "      <td>34.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>287.65</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1405</td>\n",
       "      <td>165.01</td>\n",
       "      <td>101.86</td>\n",
       "      <td>105.47</td>\n",
       "      <td>1.6383</td>\n",
       "      <td>28.85</td>\n",
       "      <td>...</td>\n",
       "      <td>117.2674</td>\n",
       "      <td>231.3770</td>\n",
       "      <td>123.7616</td>\n",
       "      <td>1428.79</td>\n",
       "      <td>129.50</td>\n",
       "      <td>993.98</td>\n",
       "      <td>925.22</td>\n",
       "      <td>234.37</td>\n",
       "      <td>227.08</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-25</td>\n",
       "      <td>287.15</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1368</td>\n",
       "      <td>167.24</td>\n",
       "      <td>102.41</td>\n",
       "      <td>106.04</td>\n",
       "      <td>1.6496</td>\n",
       "      <td>28.28</td>\n",
       "      <td>...</td>\n",
       "      <td>117.9946</td>\n",
       "      <td>232.3895</td>\n",
       "      <td>123.7616</td>\n",
       "      <td>1385.93</td>\n",
       "      <td>126.48</td>\n",
       "      <td>974.83</td>\n",
       "      <td>886.93</td>\n",
       "      <td>216.82</td>\n",
       "      <td>233.00</td>\n",
       "      <td>32.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>282.75</td>\n",
       "      <td>0.191</td>\n",
       "      <td>1311</td>\n",
       "      <td>166.85</td>\n",
       "      <td>104.92</td>\n",
       "      <td>107.85</td>\n",
       "      <td>1.6106</td>\n",
       "      <td>28.22</td>\n",
       "      <td>...</td>\n",
       "      <td>120.5100</td>\n",
       "      <td>231.9417</td>\n",
       "      <td>122.3281</td>\n",
       "      <td>1385.31</td>\n",
       "      <td>129.19</td>\n",
       "      <td>1007.12</td>\n",
       "      <td>842.60</td>\n",
       "      <td>201.89</td>\n",
       "      <td>237.48</td>\n",
       "      <td>31.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-08</td>\n",
       "      <td>298.40</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1277</td>\n",
       "      <td>165.43</td>\n",
       "      <td>104.22</td>\n",
       "      <td>109.30</td>\n",
       "      <td>1.6108</td>\n",
       "      <td>28.02</td>\n",
       "      <td>...</td>\n",
       "      <td>118.7914</td>\n",
       "      <td>237.8117</td>\n",
       "      <td>122.3281</td>\n",
       "      <td>1411.95</td>\n",
       "      <td>134.67</td>\n",
       "      <td>1034.58</td>\n",
       "      <td>945.15</td>\n",
       "      <td>218.00</td>\n",
       "      <td>258.02</td>\n",
       "      <td>31.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y       Data  XAU BGNL  ECSURPUS  BDIY     CRY     DXY     JPY     GBP  \\\n",
       "0  0 2000-01-11    283.25     0.077  1388  157.26  100.56  105.86  1.6460   \n",
       "1  0 2000-01-18    287.65     0.043  1405  165.01  101.86  105.47  1.6383   \n",
       "2  0 2000-01-25    287.15     0.135  1368  167.24  102.41  106.04  1.6496   \n",
       "3  0 2000-02-01    282.75     0.191  1311  166.85  104.92  107.85  1.6106   \n",
       "4  1 2000-02-08    298.40     0.312  1277  165.43  104.22  109.30  1.6108   \n",
       "\n",
       "     Cl1  ...  LP01TREU  EMUSTRUU  LF94TRUU     MXUS    MXEU     MXJP    MXBR  \\\n",
       "0  25.77  ...  116.4635  230.5267  123.7616  1416.12  127.75   990.59  856.76   \n",
       "1  28.85  ...  117.2674  231.3770  123.7616  1428.79  129.50   993.98  925.22   \n",
       "2  28.28  ...  117.9946  232.3895  123.7616  1385.93  126.48   974.83  886.93   \n",
       "3  28.22  ...  120.5100  231.9417  122.3281  1385.31  129.19  1007.12  842.60   \n",
       "4  28.02  ...  118.7914  237.8117  122.3281  1411.95  134.67  1034.58  945.15   \n",
       "\n",
       "     MXRU    MXIN   MXCN  \n",
       "0  224.33  217.34  34.30  \n",
       "1  234.37  227.08  32.74  \n",
       "2  216.82  233.00  32.46  \n",
       "3  201.89  237.48  31.29  \n",
       "4  218.00  258.02  31.32  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ews_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u9sERe9x13Vq"
   },
   "outputs": [],
   "source": [
    "# Separating features and target variable\n",
    "\n",
    "features = ews_data.drop(columns=[\"Y\", \"Data\"])  # here Data represents the date column (mispelled)\n",
    "target = ews_data[\"Y\"]\n",
    "\n",
    "# Handling missing values using mean imputation\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "features_imputed = pd.DataFrame(imputer.fit_transform(features), columns=features.columns)\n",
    "\n",
    "# Scaling features for uniformity\n",
    "scaler = StandardScaler()\n",
    "features_scaled = pd.DataFrame(scaler.fit_transform(features_imputed), columns=features.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "s66WF4p81-2Z",
    "outputId": "9026b772-8c08-4ff2-f8e8-da3e7a4e00ac"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(features_scaled, target)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.1, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Training an Isolation Forest model \n",
    "model = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1oG9hfv2NO1",
    "outputId": "c0f25b2d-911e-412b-c16a-bd85fb009e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.67       179\n",
      "           1       0.59      0.13      0.21       171\n",
      "\n",
      "    accuracy                           0.53       350\n",
      "   macro avg       0.56      0.52      0.44       350\n",
      "weighted avg       0.56      0.53      0.44       350\n",
      "\n",
      "ROC-AUC Score: 0.5224280440393348\n"
     ]
    }
   ],
   "source": [
    "# Predicting anomalies and evaluating the model\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Converting Isolation Forest outputs (-1 for anomaly, 1 for normal) to binary classification\n",
    "y_pred_test_binary = [1 if pred == -1 else 0 for pred in y_pred_test]\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test_binary))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90       179\n",
      "           1       0.85      0.98      0.91       171\n",
      "\n",
      "    accuracy                           0.91       350\n",
      "   macro avg       0.91      0.91      0.91       350\n",
      "weighted avg       0.92      0.91      0.91       350\n",
      "\n",
      "ROC-AUC Score: 0.98503708059721\n"
     ]
    }
   ],
   "source": [
    "# a Random Forest classifier with hyperparameter tuning\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_pred_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust threshold for classification\n",
    "threshold = 0.4\n",
    "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imputer.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(best_rf, \"rf_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(imputer, \"imputer.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
